{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "'''Modified from sklearn documentation: https://scikit-learn.org/stable/modules/compose.html\n",
    "'''\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LogisticRegression, Ridge,RidgeCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score,r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.utils\n",
    "import os\n",
    "import sys\n",
    "from functools import partial\n",
    "import itertools\n",
    "import networkx as nx\n",
    "np.set_printoptions(threshold=5) # to limit printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "import pcsp\n",
    "from pcsp import PCSPipeline, ModuleSet, Module, init_args # must install pcsp first (pip install pcsp)\n",
    "from pcsp.pipeline import build_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('X_train', 'y_train', 'subsampling_0', 'LR', 'X_test'),\n",
       "  'y_test',\n",
       "  'Acc'): 0.9230769230769231,\n",
       " (('X_train', 'y_train', 'subsampling_0', 'LR', 'X_test'),\n",
       "  'y_test',\n",
       "  'Bal_Acc'): 0.9444444444444444,\n",
       " (('X_train', 'y_train', 'subsampling_0', 'DT', 'X_test'),\n",
       "  'y_test',\n",
       "  'Acc'): 0.7692307692307693,\n",
       " (('X_train', 'y_train', 'subsampling_0', 'DT', 'X_test'),\n",
       "  'y_test',\n",
       "  'Bal_Acc'): 0.7638888888888888,\n",
       " (('X_train', 'y_train', 'subsampling_1', 'LR', 'X_test'),\n",
       "  'y_test',\n",
       "  'Acc'): 0.9230769230769231,\n",
       " (('X_train', 'y_train', 'subsampling_1', 'LR', 'X_test'),\n",
       "  'y_test',\n",
       "  'Bal_Acc'): 0.9444444444444444,\n",
       " (('X_train', 'y_train', 'subsampling_1', 'DT', 'X_test'),\n",
       "  'y_test',\n",
       "  'Acc'): 0.8461538461538461,\n",
       " (('X_train', 'y_train', 'subsampling_1', 'DT', 'X_test'),\n",
       "  'y_test',\n",
       "  'Bal_Acc'): 0.9,\n",
       " (('X_train', 'y_train', 'subsampling_2', 'LR', 'X_test'),\n",
       "  'y_test',\n",
       "  'Acc'): 0.8461538461538461,\n",
       " (('X_train', 'y_train', 'subsampling_2', 'LR', 'X_test'),\n",
       "  'y_test',\n",
       "  'Bal_Acc'): 0.8375,\n",
       " (('X_train', 'y_train', 'subsampling_2', 'DT', 'X_test'),\n",
       "  'y_test',\n",
       "  'Acc'): 0.8461538461538461,\n",
       " (('X_train', 'y_train', 'subsampling_2', 'DT', 'X_test'),\n",
       "  'y_test',\n",
       "  'Bal_Acc'): 0.8375,\n",
       " '__prev__': <pcsp.module_set.ModuleSet at 0x1345a95b0>}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize data\n",
    "np.random.seed(13)\n",
    "X, y = sklearn.datasets.make_classification(n_samples=50, n_features=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) # ex. with another split?\n",
    "X_train, X_test, y_train, y_test = init_args((X_train, X_test, y_train, y_test), # could run this line higher (on X, y)\n",
    "                                              names=['X_train', 'X_test', 'y_train', 'y_test'])  # optionally provide names for each of these\n",
    "\n",
    "# subsample data\n",
    "subsampling_funcs = [partial(sklearn.utils.resample,\n",
    "                            n_samples=20,\n",
    "                            random_state=i)\n",
    "                     for i in range(3)]\n",
    "subsampling_set = ModuleSet(name='subsampling',\n",
    "                            modules=subsampling_funcs)\n",
    "X_trains, y_trains = subsampling_set(X_train, y_train) # subsampling_set([X_train, X_train], [y_train, y_train]) # artificially make it seem like there are multiple dsets (data_0 and data_1)\n",
    "\n",
    "\n",
    "#fit models\n",
    "modeling_set = ModuleSet(name='modeling',\n",
    "                          modules=[LogisticRegression(max_iter=1000, tol=0.1),\n",
    "                                   DecisionTreeClassifier()],\n",
    "                          module_keys=[\"LR\", \"DT\"], out={})\n",
    "\n",
    "modeling_set.fit(X_trains, y_trains)\n",
    "preds_test = modeling_set.predict(X_test)\n",
    "\n",
    "# get metrics\n",
    "hard_metrics_set = ModuleSet(name='hard_metrics',\n",
    "                              modules=[accuracy_score, balanced_accuracy_score],\n",
    "                              module_keys=[\"Acc\", \"Bal_Acc\"], out={})\n",
    "\n",
    "hard_metrics = hard_metrics_set.evaluate(preds_test, y_test)\n",
    "# #hard_metrics.__prev__[0]\n",
    " #inspect the pipeline\n",
    "#for k1, v1 in hard_metrics.items():\n",
    "#     print(k1)\n",
    "# G = build_graph(hard_metrics, draw=True)\n",
    "# plt.show()\n",
    "hard_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('X_train',\n",
       "  'y_train',\n",
       "  'subsampling_0'): array([[-0.30582021, -0.97541273, -1.15871714, -1.35132194, -0.54657674],\n",
       "        [-1.43494529,  1.1326585 , -0.83681009,  0.13067855, -0.84447641],\n",
       "        [-1.43494529,  1.1326585 , -0.83681009,  0.13067855, -0.84447641],\n",
       "        ...,\n",
       "        [-0.2177465 , -1.02788437, -1.09361985, -1.34001946,  0.89179417],\n",
       "        [-0.1629447 , -1.15701078, -1.13084551, -1.44233728,  0.40067367],\n",
       "        [ 1.07469058, -0.93785005,  0.55456857, -0.19937499, -0.88249039]]),\n",
       " ('X_train',\n",
       "  'y_train',\n",
       "  'subsampling_1'): array([[-1.48243722,  0.76640114, -1.1897997 , -0.3226144 ,  0.35136153],\n",
       "        [-0.1629447 , -1.15701078, -1.13084551, -1.44233728,  0.40067367],\n",
       "        [ 1.07469058, -0.93785005,  0.55456857, -0.19937499, -0.88249039],\n",
       "        ...,\n",
       "        [-0.11906892,  1.93190004,  1.41135673,  2.09399849, -0.41926032],\n",
       "        [ 0.06323364, -1.00202171, -0.73023127, -1.08491149, -0.86779981],\n",
       "        [-0.4063791 , -1.53317147, -1.73069344, -2.06431346, -0.7645939 ]]),\n",
       " ('X_train',\n",
       "  'y_train',\n",
       "  'subsampling_2'): array([[-0.21948271,  2.08284284,  1.41055276,  2.18439017, -0.68623644],\n",
       "        [-0.1629447 , -1.15701078, -1.13084551, -1.44233728,  0.40067367],\n",
       "        [-1.47232803,  1.09490649, -0.91280101,  0.05784853,  0.78857048],\n",
       "        ...,\n",
       "        [-0.90695435, -1.89701941, -2.63410913, -2.87897116, -1.01700203],\n",
       "        [-1.35884162,  0.85250676, -0.96974597, -0.12569848, -2.2068671 ],\n",
       "        [-1.08400954,  0.86756978, -0.62255386,  0.11222826, -0.67537506]]),\n",
       " '__prev__': <pcsp.module_set.ModuleSet at 0x134559610>}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('X_train', 'y_train', 'subsampling_0'): array([0, 0, 0, ..., 0, 0, 1]),\n",
       " ('X_train', 'y_train', 'subsampling_1'): array([0, 0, 1, ..., 1, 0, 0]),\n",
       " ('X_train', 'y_train', 'subsampling_2'): array([1, 0, 0, ..., 0, 0, 0]),\n",
       " '__prev__': <pcsp.module_set.ModuleSet at 0x134559610>}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering pipeline\n",
    "**this data set predicts boston house-preices dataset (regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhineetagarwal/miniforge3/envs/pcsp-env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:1421: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  w = ((singvals_sq + alpha) ** -1) - (alpha ** -1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(((('X_train', 'feat_extraction_0'), 'y_train', 'Ridge'),\n",
       "   ('X_train', 'feat_extraction_0')),\n",
       "  'y_train',\n",
       "  'r2'): 0.998077138036731,\n",
       " (((('X_train', 'feat_extraction_0'), 'y_train', 'DT'),\n",
       "   ('X_train', 'feat_extraction_0')),\n",
       "  'y_train',\n",
       "  'r2'): -1.1560645978534585,\n",
       " (((('X_train', 'feat_extraction_1'), 'y_train', 'Ridge'),\n",
       "   ('X_train', 'feat_extraction_1')),\n",
       "  'y_train',\n",
       "  'r2'): 1.0,\n",
       " (((('X_train', 'feat_extraction_1'), 'y_train', 'DT'),\n",
       "   ('X_train', 'feat_extraction_1')),\n",
       "  'y_train',\n",
       "  'r2'): 0.34917016148850655,\n",
       " '__prev__': <pcsp.module_set.ModuleSet at 0x1345a9670>}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data as df\n",
    "np.random.seed(13)\n",
    "data = sklearn.datasets.load_boston()\n",
    "df = pd.DataFrame.from_dict(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = init_args(train_test_split(df, y, random_state=123),\n",
    "                                             names=['X_train', 'X_test', 'y_train', 'y_test'])\n",
    "\n",
    "\n",
    "# feature extraction - extracts two different sets of features from the same data\n",
    "def extract_feats(df: pd.DataFrame, feat_names=['CRIM', 'ZN', 'INDUS', 'CHAS']):\n",
    "    '''extract specific columns from dataframe\n",
    "    '''\n",
    "    return df[feat_names]\n",
    "feat_extraction_funcs = [partial(extract_feats, feat_names=['CRIM', 'ZN', 'INDUS', 'CHAS']),\n",
    "                         partial(extract_feats, feat_names=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE']),\n",
    "                        ]\n",
    "feat_extraction = ModuleSet(name='feat_extraction',\n",
    "                            modules=feat_extraction_funcs)\n",
    "\n",
    "X_feats_train = feat_extraction(X_train)\n",
    "X_feats_test = feat_extraction(X_test)\n",
    "\n",
    "\n",
    "\n",
    "modeling_set = ModuleSet(name='modeling',\n",
    "                         modules=[#RidgeCV(max_iter=1000, tol=0.1),\n",
    "                                  \n",
    "                                  DecisionTreeRegressor(),RidgeCV()],\n",
    "                         module_keys=[\"Ridge\", \"DT\"])\n",
    "\n",
    "# how can we properly pass a y here so that it will fit properly?\n",
    "# this runs, but modeling_set.out is empty\n",
    "_ = modeling_set.fit(X_feats_train,y_train)\n",
    "\n",
    "# #get predictions\n",
    "preds_all = modeling_set.predict(X_feats_train)\n",
    "\n",
    "# y_test_dict = {('data_0', 'feat_extraction_0'): y_test['X_test'], ('data_0', 'feat_extraction_1'): y_test['X_test']}\n",
    "\n",
    "#get metrics\n",
    "hard_metrics_set = ModuleSet(name='hard_metrics',\n",
    "                              modules=[r2_score],\n",
    "                             module_keys=[\"r2\"])\n",
    "hard_metrics = hard_metrics_set.evaluate(preds_all, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# inspect the pipeline\n",
    "#for k in hard_metrics:\n",
    "#     print(k, hard_metrics[k])\n",
    "#G = build_graph(hard_metrics, draw=True)\n",
    "#plt.show()\n",
    "hard_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{((('X_train', 'feat_extraction_0'), 'y_train', 'Ridge'),\n",
       "  ('X_train',\n",
       "   'feat_extraction_0')): array([25.21976108, 22.22680587, 18.18331619, ..., 24.11794761,\n",
       "        17.0338256 , 18.10485095]),\n",
       " ((('X_train', 'feat_extraction_0'), 'y_train', 'DT'),\n",
       "  ('X_train',\n",
       "   'feat_extraction_0')): array([21.1, 13.4, 17.4, ..., 20.4, 11.3, 27.5]),\n",
       " ((('X_train', 'feat_extraction_1'), 'y_train', 'Ridge'),\n",
       "  ('X_train',\n",
       "   'feat_extraction_1')): array([22.64986892, 15.6034198 , 17.43978791, ..., 21.96476899,\n",
       "        13.32102878, -0.80179865]),\n",
       " ((('X_train', 'feat_extraction_1'), 'y_train', 'DT'),\n",
       "  ('X_train',\n",
       "   'feat_extraction_1')): array([21.1, 13.4, 17.4, ..., 20.4, 11.3, 27.5]),\n",
       " '__prev__': <pcsp.module_set.ModuleSet at 0x1345ac5e0>}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ridge': Ridge(max_iter=1000, tol=0.1), 'DT': DecisionTreeRegressor()}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(X_feats_train) \n",
    "#X_feats_train(),still weird that this is a list\n",
    "#X_feats_train\n",
    "# TODO: this is broken atm.. may want to preserve ModuleSet.modules in their original form of modules / functions\n",
    "#X_feats_test = feat_extraction(X_test) # still weird that this is a list\n",
    "#fit models\n",
    "#y = {\n",
    "#     'data_0': y_train,\n",
    "#     'data_1': y_test\n",
    "#}\n",
    "\n",
    "#y_train_dict = {('X_train', 'feat_extraction_0'): y_train['X_train'], ('X_train', 'feat_extraction_1'): y_train['X_train']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tracking things w Pipeline (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PCSPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.steps = [subsampling_set, modeling_set, hard_metrics_set] # how to deal w/ hard metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broken\n",
    "# p.run(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': <function sklearn.metrics._regression.r2_score(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.steps[2].modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broken\n",
    "#df = p.generate_names()\n",
    "#df['hard_metrics'] = hard_metrics\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
