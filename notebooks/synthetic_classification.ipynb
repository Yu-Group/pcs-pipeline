{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "'''Modified from sklearn documentation: https://scikit-learn.org/stable/modules/compose.html\n",
    "'''\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from pcsp import PCSPipeline, ModuleSet, Module # must install pcsp first (pip install pcsp)\n",
    "from pcsp.module_set import to_tuple, to_list\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from functools import partial\n",
    "import itertools\n",
    "np.set_printoptions(threshold=5) # to limit printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('data_0', 'subsampling_0', 'LR'), ('data_0', 'subsampling_0'), 'Acc') 0.9090909090909091\n",
      "(('data_0', 'subsampling_0', 'LR'), ('data_0', 'subsampling_0'), 'Bal_Acc') 0.8333333333333333\n",
      "(('data_0', 'subsampling_0', 'DT'), ('data_0', 'subsampling_0'), 'Acc') 0.9090909090909091\n",
      "(('data_0', 'subsampling_0', 'DT'), ('data_0', 'subsampling_0'), 'Bal_Acc') 0.8333333333333333\n",
      "(('data_0', 'subsampling_1', 'LR'), ('data_0', 'subsampling_0'), 'Acc') 0.9090909090909091\n",
      "(('data_0', 'subsampling_1', 'LR'), ('data_0', 'subsampling_0'), 'Bal_Acc') 0.8333333333333333\n",
      "(('data_0', 'subsampling_1', 'DT'), ('data_0', 'subsampling_0'), 'Acc') 0.9090909090909091\n",
      "(('data_0', 'subsampling_1', 'DT'), ('data_0', 'subsampling_0'), 'Bal_Acc') 0.8333333333333333\n",
      "(('data_0', 'subsampling_2', 'LR'), ('data_0', 'subsampling_0'), 'Acc') 0.9090909090909091\n",
      "(('data_0', 'subsampling_2', 'LR'), ('data_0', 'subsampling_0'), 'Bal_Acc') 0.8333333333333333\n",
      "(('data_0', 'subsampling_2', 'DT'), ('data_0', 'subsampling_0'), 'Acc') 0.9090909090909091\n",
      "(('data_0', 'subsampling_2', 'DT'), ('data_0', 'subsampling_0'), 'Bal_Acc') 0.8333333333333333\n",
      "(('data_0', 'subsampling_0', 'LR'), ('data_0', 'subsampling_1'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_0', 'LR'), ('data_0', 'subsampling_1'), 'Bal_Acc') 1.0\n",
      "(('data_0', 'subsampling_0', 'DT'), ('data_0', 'subsampling_1'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_0', 'DT'), ('data_0', 'subsampling_1'), 'Bal_Acc') 1.0\n",
      "(('data_0', 'subsampling_1', 'LR'), ('data_0', 'subsampling_1'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_1', 'LR'), ('data_0', 'subsampling_1'), 'Bal_Acc') 1.0\n",
      "(('data_0', 'subsampling_1', 'DT'), ('data_0', 'subsampling_1'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_1', 'DT'), ('data_0', 'subsampling_1'), 'Bal_Acc') 1.0\n",
      "(('data_0', 'subsampling_2', 'LR'), ('data_0', 'subsampling_1'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_2', 'LR'), ('data_0', 'subsampling_1'), 'Bal_Acc') 1.0\n",
      "(('data_0', 'subsampling_2', 'DT'), ('data_0', 'subsampling_1'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_2', 'DT'), ('data_0', 'subsampling_1'), 'Bal_Acc') 1.0\n",
      "(('data_0', 'subsampling_0', 'LR'), ('data_0', 'subsampling_2'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_0', 'LR'), ('data_0', 'subsampling_2'), 'Bal_Acc') 1.0\n",
      "(('data_0', 'subsampling_0', 'DT'), ('data_0', 'subsampling_2'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_0', 'DT'), ('data_0', 'subsampling_2'), 'Bal_Acc') 1.0\n",
      "(('data_0', 'subsampling_1', 'LR'), ('data_0', 'subsampling_2'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_1', 'LR'), ('data_0', 'subsampling_2'), 'Bal_Acc') 1.0\n",
      "(('data_0', 'subsampling_1', 'DT'), ('data_0', 'subsampling_2'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_1', 'DT'), ('data_0', 'subsampling_2'), 'Bal_Acc') 1.0\n",
      "(('data_0', 'subsampling_2', 'LR'), ('data_0', 'subsampling_2'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_2', 'LR'), ('data_0', 'subsampling_2'), 'Bal_Acc') 1.0\n",
      "(('data_0', 'subsampling_2', 'DT'), ('data_0', 'subsampling_2'), 'Acc') 1.0\n",
      "(('data_0', 'subsampling_2', 'DT'), ('data_0', 'subsampling_2'), 'Bal_Acc') 1.0\n",
      "('data_0', 'subsampling_0', 'LR', 'test', 'Acc') 0.8461538461538461\n",
      "('data_0', 'subsampling_0', 'LR', 'test', 'Bal_Acc') 0.8375\n",
      "('data_0', 'subsampling_0', 'DT', 'test', 'Acc') 0.8461538461538461\n",
      "('data_0', 'subsampling_0', 'DT', 'test', 'Bal_Acc') 0.8375\n",
      "('data_0', 'subsampling_1', 'LR', 'test', 'Acc') 0.8461538461538461\n",
      "('data_0', 'subsampling_1', 'LR', 'test', 'Bal_Acc') 0.8375\n",
      "('data_0', 'subsampling_1', 'DT', 'test', 'Acc') 0.8461538461538461\n",
      "('data_0', 'subsampling_1', 'DT', 'test', 'Bal_Acc') 0.8375\n",
      "('data_0', 'subsampling_2', 'LR', 'test', 'Acc') 0.8461538461538461\n",
      "('data_0', 'subsampling_2', 'LR', 'test', 'Bal_Acc') 0.8375\n",
      "('data_0', 'subsampling_2', 'DT', 'test', 'Acc') 0.8461538461538461\n",
      "('data_0', 'subsampling_2', 'DT', 'test', 'Bal_Acc') 0.8375\n",
      "__prev__ ModuleSet(hard_metrics)\n"
     ]
    }
   ],
   "source": [
    "# subsample data\n",
    "np.random.seed(13)\n",
    "X, y = make_classification(n_samples=50, n_features=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "subsampling_funcs = [partial(resample,\n",
    "                            n_samples=int(X_train.shape[0]*0.3),\n",
    "                            random_state=i)\n",
    "                     for i in range(3)]\n",
    "subsampling_set = ModuleSet(name='subsampling',\n",
    "                            modules=subsampling_funcs)\n",
    "X_all, y_all = subsampling_set([X_train], [y_train]) # subsampling_set([X_train, X_train], [y_train, y_train]) # artificially make it seem like there are multiple dsets (data_0 and data_1)\n",
    "\n",
    "# fit models\n",
    "modeling_set = ModuleSet(name='modeling',\n",
    "                         modules=[LogisticRegression(max_iter=1000, tol=0.1),\n",
    "                                  DecisionTreeClassifier()],\n",
    "                         module_keys=[\"LR\", \"DT\"])\n",
    "models = modeling_set.fit(X_all, y_all)  # ModuleSet needs to store something for this call to work (makes models kind of useless)\n",
    "\n",
    "# get predictions\n",
    "X_all[\"test\"] = X_test\n",
    "y_all[\"test\"] = y_test\n",
    "preds_all = modeling_set.predict(X_all)\n",
    "\n",
    "# get metrics\n",
    "hard_metrics_set = ModuleSet(name='hard_metrics',\n",
    "                             modules=[accuracy_score, balanced_accuracy_score],\n",
    "                             module_keys=[\"Acc\", \"Bal_Acc\"])\n",
    "hard_metrics = hard_metrics_set.evaluate(y_all, preds_all)\n",
    "for k in hard_metrics:\n",
    "    print(k, hard_metrics[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ModuleSet(modeling)'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(preds_all['__prev__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample data\n",
    "np.random.seed(13)\n",
    "X, y = make_classification(n_samples=50, n_features=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "subsampling_funcs = [partial(resample,\n",
    "                            n_samples=int(X_train.shape[0]*0.3),\n",
    "                            random_state=i)\n",
    "                     for i in range(3)]\n",
    "subsampling_set = ModuleSet(name='subsampling',\n",
    "                            modules=subsampling_funcs)\n",
    "X_all, y_all = subsampling_set([X_train], [y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('data_0',\n",
       "  'subsampling_0'): array([[-0.30582021, -0.97541273, -1.15871714, -1.35132194, -0.54657674],\n",
       "        [-1.43494529,  1.1326585 , -0.83681009,  0.13067855, -0.84447641],\n",
       "        [-1.43494529,  1.1326585 , -0.83681009,  0.13067855, -0.84447641],\n",
       "        ...,\n",
       "        [-0.20317177, -0.50101282, -0.65135496, -0.73113299, -0.93235926],\n",
       "        [-1.35884162,  0.85250676, -0.96974597, -0.12569848, -2.2068671 ],\n",
       "        [-1.35884162,  0.85250676, -0.96974597, -0.12569848, -2.2068671 ]]),\n",
       " ('data_0',\n",
       "  'subsampling_1'): array([[-1.48243722,  0.76640114, -1.1897997 , -0.3226144 ,  0.35136153],\n",
       "        [-0.1629447 , -1.15701078, -1.13084551, -1.44233728,  0.40067367],\n",
       "        [ 1.07469058, -0.93785005,  0.55456857, -0.19937499, -0.88249039],\n",
       "        ...,\n",
       "        [-1.22242099,  0.8517753 , -0.80402087, -0.01690056,  0.2283352 ],\n",
       "        [-1.48243722,  0.76640114, -1.1897997 , -0.3226144 ,  0.35136153],\n",
       "        [-1.70489766,  1.13784372, -1.16173936, -0.08037683, -0.403129  ]]),\n",
       " ('data_0',\n",
       "  'subsampling_2'): array([[-0.21948271,  2.08284284,  1.41055276,  2.18439017, -0.68623644],\n",
       "        [-0.1629447 , -1.15701078, -1.13084551, -1.44233728,  0.40067367],\n",
       "        [-1.47232803,  1.09490649, -0.91280101,  0.05784853,  0.78857048],\n",
       "        ...,\n",
       "        [ 0.46471202,  0.94169877,  1.32526378,  1.4407941 ,  2.3867458 ],\n",
       "        [-0.91015634,  1.17107093, -0.16607569,  0.59593449, -0.94663646],\n",
       "        [-0.03122652, -1.25384759, -1.04828466, -1.44624733,  0.14375578]]),\n",
       " '__prev__': <pcsp.module_set.ModuleSet at 0x7fa0a0fba6a0>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Subsampling module set\n",
    "\n",
    "X, y = make_classification(n_samples=50, n_features=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "subsampling_keys = [\"subsampling_1\",\"subsampling_2\",\"subsampling_3\"]\n",
    "subsampling_funcs = [partial(resample,\n",
    "                            n_samples=int(X_train.shape[0]*0.3),\n",
    "                            random_state=i)\n",
    "                     for i in range(3)]\n",
    "subsampling_mods = dict(zip(subsampling_keys, subsampling_funcs))\n",
    "subsampling_set = ModuleSet(name='subsampling', modules=subsampling_mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = subsampling_set([X_train, X_train], [y_train, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampling_set.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_funcs = [LogisticRegression(max_iter=1000, tol=0.1), DecisionTreeClassifier()]\n",
    "modeling_keys = [\"LR\",\"DT\"]\n",
    "modeling_mods = dict(zip(modeling_keys,modeling_funcs))\n",
    "modeling_set = ModuleSet(name = 'modeling', modules = modeling_mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('data_0', 'subsampling_1', 'LR'): LogisticRegression(max_iter=1000, tol=0.1),\n",
       " ('data_0', 'subsampling_1', 'DT'): DecisionTreeClassifier(),\n",
       " ('data_0', 'subsampling_2', 'LR'): LogisticRegression(max_iter=1000, tol=0.1),\n",
       " ('data_0', 'subsampling_2', 'DT'): DecisionTreeClassifier(),\n",
       " ('data_0', 'subsampling_3', 'LR'): LogisticRegression(max_iter=1000, tol=0.1),\n",
       " ('data_0', 'subsampling_3', 'DT'): DecisionTreeClassifier(),\n",
       " ('data_1', 'subsampling_1', 'LR'): LogisticRegression(max_iter=1000, tol=0.1),\n",
       " ('data_1', 'subsampling_1', 'DT'): DecisionTreeClassifier(),\n",
       " ('data_1', 'subsampling_2', 'LR'): LogisticRegression(max_iter=1000, tol=0.1),\n",
       " ('data_1', 'subsampling_2', 'DT'): DecisionTreeClassifier(),\n",
       " ('data_1', 'subsampling_3', 'LR'): LogisticRegression(max_iter=1000, tol=0.1),\n",
       " ('data_1', 'subsampling_3', 'DT'): DecisionTreeClassifier()}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = modeling_set.fit(subsampling_set.modules)\n",
    "models\n",
    "#train = [X_train,y_train]\n",
    "#x = LogisticRegression(max_iter=1000, tol=0.1).fit\n",
    "#x(*subsampling_set.modules[('item_0','subsampling_1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"test\"] = X_test\n",
    "preds = modeling_set.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard-Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[\"test\"] = y_test\n",
    "hard_metrics_funcs = [accuracy_score, balanced_accuracy_score]\n",
    "hard_metrics_keys = [\"Acc\",\"Bal_Acc\"] \n",
    "hard_metrics_mods = dict(zip(hard_metrics_keys,hard_metrics_funcs))\n",
    "hard_metrics_set = ModuleSet(name='hard_metrics', modules=hard_metrics_mods)\n",
    "hard_metrics_set.evaluate(y,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('data_0', 'subsampling_1'): array([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1]),\n",
       " ('data_0', 'subsampling_2'): array([1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " ('data_0', 'subsampling_3'): array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1]),\n",
       " ('data_1', 'subsampling_1'): array([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1]),\n",
       " ('data_1', 'subsampling_2'): array([1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " ('data_1', 'subsampling_3'): array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1]),\n",
       " 'test': array([1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tracking things w Pipeline (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PCSPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.steps = [subsampling_set, modeling_set, soft_metrics_set] # how to deal w/ hard metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.run([X_train], [y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = p.generate_names()\n",
    "df['soft_metrics'] = soft_metrics\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
